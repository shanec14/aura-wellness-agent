{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJHLHoEMrJ7R"
   },
   "source": [
    "# AURA: Adaptive Understanding & Recovery Assistant  \n",
    "*Mind–Body Insight Through Data-Driven Coaching*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to AURA — a personalised LLM-based wellness assistant that integrates your **biometric data**, **daily journals**, **work productivity logs**, and **weather conditions** into one intelligent interface for **self-reflection, insight, and performance coaching**.\n",
    "\n",
    "### Why AURA?\n",
    "While tools like ChatGPT can give general health advice, they lack personal context. AURA changes that — offering insight **based on your actual lived experience**, not generic recommendations.\n",
    "\n",
    "### What Makes AURA Unique?\n",
    "- **File Search** over daily journals to surface emotional patterns.\n",
    "- **Function Calling** to pull real-time data from:\n",
    "  - **WHOOP**: sleep, strain, HRV, recovery\n",
    "  - **Notion**: deep work, off-task time, breaks\n",
    "  - **Weather API**: temperature and conditions\n",
    "- **Code Interpreter** to analyse correlations and visualise trends.\n",
    "\n",
    "### What Can You Ask AURA?\n",
    "- “Did my deep sleep affect focus this week?”\n",
    "- “What caused my low recovery on April 17?”\n",
    "- “What should I do more of next week based on this week’s performance?”\n",
    "- “How did weather impact mood and productivity last week?”\n",
    "\n",
    "### Core Vision\n",
    "AURA acts as a **data scientist meets wellness coach** — one who knows your patterns and can explain them clearly, visually, and intelligently. It’s not just an assistant that chats — it **thinks, analyses, and guides**.\n",
    "\n",
    "---\n",
    ">  *Please avoid using \"Run all\" so that the worked examples will remain in the the cell outputs.*\n",
    "\n",
    ">  *Please make sure to enable Drive access and store API keys in Colab’s `userdata`. Full setup instructions follow below.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnvOQ51PjSzn"
   },
   "source": [
    "#  Setup & Drive Mount\n",
    "\n",
    "This notebook contains all the code for my custom LLM assistant using OpenAI’s Assistants API.  \n",
    "Please make sure to **enable access to your Google Drive** when prompted — this is required to load files and credentials.\n",
    "\n",
    ">  **IMPORTANT**: API keys are retrieved using `userdata`, so ensure you have them stored before proceeding:\n",
    "- `OpenAIKey`, `OpenWeatherKey`, `NotionToken`, `NotionDatabaseID`\n",
    "- `WHOOPClientID`, `WHOOPClientSecret`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLRZBLngV8ZV"
   },
   "source": [
    "## Set Working Directory\n",
    "\n",
    "Update this path if you've saved the journal text file elsewhere in your Drive:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/GenAIProject\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = \"/content/drive/MyDrive/GenAIProject\"\n",
    "%cd {BASE_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQEzi8XUnmjG"
   },
   "source": [
    "## Enviroment Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
      "Collecting notion-client\n",
      "  Downloading notion_client-2.3.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
      "Requirement already satisfied: requests_oauthlib in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests_oauthlib) (3.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Downloading notion_client-2.3.0-py2.py3-none-any.whl (13 kB)\n",
      "Installing collected packages: notion-client\n",
      "Successfully installed notion-client-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai notion-client requests requests_oauthlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "from openai import OpenAI\n",
    "from notion_client import Client\n",
    "import requests\n",
    "from requests_oauthlib import OAuth2Session\n",
    "\n",
    "from google.colab import drive, userdata\n",
    "from IPython.display import display, Markdown, Image\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZHq2FyUnrJ7"
   },
   "source": [
    "## Load API Keys\n",
    "\n",
    "These are accessed via Colab `userdata`, which ensures no hardcoding of keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Credientials\n",
    "OPENAI_API_KEY = userdata.get('OpenAIKey')\n",
    "\n",
    "# Open Weather Credentials\n",
    "OPENWEATHER_API_KEY = userdata.get(\"OpenWeatherKey\")\n",
    "\n",
    "# Notion credentials\n",
    "notion_token = userdata.get(\"NotionToken\")\n",
    "database_id = userdata.get(\"NotionDatabaseID\")\n",
    "\n",
    "# WHOOP credentials\n",
    "WHOOP_client_id= userdata.get(\"WHOOPClientID\")\n",
    "WHOOP_client_secret = userdata.get(\"WHOOPClientSecret\")\n",
    "\n",
    "\n",
    "print(\"API keys loaded\")\n",
    "print(f\"Whoope client id Key: {WHOOP_client_id}...\")\n",
    "print(f\"WHOOP_client_secret: {WHOOP_client_secret}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mbT5usyhKsD"
   },
   "source": [
    "## Weather API Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_location(location):\n",
    "    \"\"\"\n",
    "    Converts a human-readable location name into geographic coordinates (latitude and longitude)\n",
    "    using the OpenWeatherMap Geocoding API.\n",
    "\n",
    "    Args:\n",
    "        location (str): Name of the location (e.g., \"Dublin\")\n",
    "\n",
    "    Returns:\n",
    "        tuple: (latitude, longitude)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the location cannot be geocoded.\n",
    "    \"\"\"\n",
    "    url = f\"http://api.openweathermap.org/geo/1.0/direct?q={location}&limit=1&appid={OPENWEATHER_API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if not data:\n",
    "        raise ValueError(f\"Could not geocode location: {location}\")\n",
    "\n",
    "    return data[0]['lat'], data[0]['lon']\n",
    "\n",
    "\n",
    "def get_weather(date: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches historical weather data (average temperature and description) for Dublin\n",
    "    on a given date using the OpenWeatherMap Time Machine API.\n",
    "\n",
    "    Args:\n",
    "        date (str): Date in the format \"YYYY-MM-DD\"\n",
    "\n",
    "    Returns:\n",
    "        str: Summary string describing the weather on the given date.\n",
    "    \"\"\"\n",
    "    location = \"Dublin\"\n",
    "\n",
    "    # Convert date string to UNIX timestamp\n",
    "    dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    unix_time = int(time.mktime(dt.timetuple()))\n",
    "\n",
    "    # Get coordinates for the specified location\n",
    "    lat, lon = geocode_location(location)\n",
    "\n",
    "    # Build the API request URL for historical weather data\n",
    "    url = f\"https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={lat}&lon={lon}&dt={unix_time}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract relevant weather data\n",
    "    daily_data = data.get(\"data\", [])\n",
    "\n",
    "    if daily_data:\n",
    "        temp = daily_data[0].get(\"temp\", 0)\n",
    "        weather_desc = daily_data[0].get(\"weather\", [{}])[0].get(\"description\", \"unknown\")\n",
    "        avg_temp_str = f\"{round(temp, 1)}°C\"\n",
    "    else:\n",
    "        avg_temp_str = \"N/A\"\n",
    "        weather_desc = \"unknown\"\n",
    "\n",
    "    return f\"On {date} in {location}, the average temperature was {avg_temp_str} and the weather was '{weather_desc}'.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7Djr7dlhTpy"
   },
   "source": [
    "## Notion API Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fetch_and_parse_notion_entries(date):\n",
    "    \"\"\"\n",
    "    Fetch and organize productivity entries from a Notion database.\n",
    "\n",
    "    Args:\n",
    "        date (str): Optional. A specific date (YYYY-MM-DD) to filter entries.\n",
    "\n",
    "    Returns:\n",
    "        dict: Aggregated productivity data either for the specified date or for all dates.\n",
    "    \"\"\"\n",
    "\n",
    "    notion = Client(auth=notion_token)\n",
    "\n",
    "    # Helper functions to safely extract property values\n",
    "    def safe_num(props, name):\n",
    "        try:\n",
    "            return props[name][\"number\"] or 0\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    def safe_formula(props, name):\n",
    "        try:\n",
    "            return props[name][\"formula\"][\"number\"] or 0\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    # Fetch entries from Notion database with optional date filtering\n",
    "    if date:\n",
    "        response = notion.databases.query(\n",
    "            database_id=database_id,\n",
    "            filter={\n",
    "                \"property\": \"Date\",\n",
    "                \"date\": {\"equals\": date}\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        response = notion.databases.query(database_id=database_id)\n",
    "\n",
    "    results = response[\"results\"]\n",
    "\n",
    "    # Initialize structure to hold productivity data per date\n",
    "    entries_by_date = defaultdict(lambda: {\n",
    "        \"deep_work_minutes\": 0,\n",
    "        \"neutral_minutes\": 0,\n",
    "        \"off_task_minutes\": 0,\n",
    "        \"intentional_break_minutes\": 0,\n",
    "        \"light_work_minutes\": 0,\n",
    "        \"total_minutes\": 0\n",
    "    })\n",
    "\n",
    "    # Parse each entry and accumulate productivity metrics\n",
    "    for page in results:\n",
    "        props = page[\"properties\"]\n",
    "        date = props[\"Date\"][\"date\"][\"start\"]\n",
    "        prod = entries_by_date[date]\n",
    "\n",
    "        prod[\"deep_work_minutes\"] += safe_num(props, \"Deep Work (min)\")\n",
    "        prod[\"neutral_minutes\"] += safe_num(props, \"Neutral / Life Admin (min)\")\n",
    "        prod[\"off_task_minutes\"] += safe_num(props, \"Off-Task (min)\")\n",
    "        prod[\"intentional_break_minutes\"] += safe_num(props, \"Intentional Break (min)\")\n",
    "        prod[\"light_work_minutes\"] += safe_num(props, \"Light Work (min)\")\n",
    "        prod[\"total_minutes\"] += safe_formula(props, \"Total Time (min)\")\n",
    "\n",
    "    # Convert total minutes to hours for readability\n",
    "    final_entries = {}\n",
    "    for date, prod in entries_by_date.items():\n",
    "      prod[\"total_hours\"] = round(prod[\"total_minutes\"] / 60, 2)\n",
    "      final_entries[date] = {\n",
    "          \"date\": date,\n",
    "          \"data\": prod\n",
    "      }\n",
    "\n",
    "\n",
    "    return final_entries.get(date) if date else final_entries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeX53reshljY"
   },
   "source": [
    "## Whoop API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk-vhAYPhoCS"
   },
   "source": [
    "### Authentifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL to authorize:\n",
      "\n",
      "https://api.prod.whoop.com/oauth/oauth2/auth?response_type=code&client_id=2009d2fc-1906-4c2b-8cf2-54b75a6b09bd&redirect_uri=http%3A%2F%2Flocalhost%3A8000%2Fcallback&scope=read%3Arecovery+read%3Asleep+read%3Aworkout+read%3Aprofile+read%3Abody_measurement+read%3Acycles&state=elZZfgfVG5iW6c4rfjAHtOmM3u6Zp5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Allow HTTP redirect URI (required for localhost)\n",
    "os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "\n",
    "\n",
    "redirect_uri = 'http://localhost:8000/callback'\n",
    "\n",
    "# WHOOP endpoints and scopes\n",
    "authorization_base_url = 'https://api.prod.whoop.com/oauth/oauth2/auth'\n",
    "token_url = 'https://api.prod.whoop.com/oauth/oauth2/token'\n",
    "scopes = [\n",
    "    \"read:recovery\", \"read:sleep\", \"read:workout\",\n",
    "    \"read:profile\", \"read:body_measurement\", \"read:cycles\"\n",
    "]\n",
    "\n",
    "# Create session and generate auth URL\n",
    "oauth = OAuth2Session(WHOOP_client_id, redirect_uri=redirect_uri, scope=scopes)\n",
    "auth_url, state = oauth.authorization_url(authorization_base_url)\n",
    "\n",
    "print(\"Go to this URL to authorize:\\n\")\n",
    "print(auth_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAldvBRUSa-n"
   },
   "source": [
    "##**Important: Instructions**\n",
    "\n",
    "\n",
    "\n",
    "1.   Click on the URL provided in the print output of the previous cell.\n",
    "2.   Log in using the following credentials:\n",
    "  - Username: shaneconroy0@gmail.com\n",
    "  - Password: Monafootball1!\n",
    "3.  After logging in, click the \"Grant\" button when prompted.\n",
    "4.  You will then be redirected to a localhost URL. This may show a \"Page Not Found\" message—this is expected. **Copy this entire URL**\n",
    "5. Proceed to run the next cell in the notebook.\n",
    "6. Paste the **URL** into the input box, and press Enter.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste the full redirect URL after authorizing: http://localhost:8000/callback?code=jfsCLMCSK13SHS7BfCxEDd3cGIRSvfRPF_51aieIjUA.Xu-SiYYeLLdbD3MluPwYVYa-6GTBaVdO7rlIU8G3URU&scope=read%3Arecovery%20read%3Asleep%20read%3Aworkout%20read%3Aprofile%20read%3Abody_measurement%20read%3Acycles&state=elZZfgfVG5iW6c4rfjAHtOmM3u6Zp5\n",
      "Access token acquired\n"
     ]
    }
   ],
   "source": [
    "# Paste the full redirect URL from the browser\n",
    "redirect_response = input(\"Paste the full redirect URL after authorizing: \")\n",
    "\n",
    "\n",
    "# Try fetching token with client credentials in the body\n",
    "token = oauth.fetch_token(\n",
    "    token_url,\n",
    "    authorization_response=redirect_response,\n",
    "    client_id=WHOOP_client_id,\n",
    "    client_secret=WHOOP_client_secret,\n",
    "    include_client_id=True\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Access token acquired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI2xc1jHn7Wq"
   },
   "source": [
    "### WHOOP Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_recovery_for_date(date: str):\n",
    "    \"\"\"\n",
    "    Retrieve WHOOP recovery metrics for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): Date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "        dict: Key recovery metrics (recovery score, HRV, etc.) or an error/message if unavailable.\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # Define the start and end timestamps in ISO format for the given date\n",
    "    start = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    end = start + timedelta(days=1)\n",
    "    start_iso = start.isoformat(timespec='seconds') + \"Z\"\n",
    "    end_iso = end.isoformat(timespec='seconds') + \"Z\"\n",
    "\n",
    "    url = f\"https://api.prod.whoop.com/developer/v1/recovery?start={start_iso}&end={end_iso}\"\n",
    "    resp = oauth.get(url)\n",
    "\n",
    "    try:\n",
    "        data = resp.json()\n",
    "        records = data.get(\"records\", [])\n",
    "\n",
    "        if not records:\n",
    "            return {\"message\": \"No recovery data found for that date\"}\n",
    "\n",
    "        # Extract relevant metrics from the first recovery record\n",
    "        score = records[0][\"score\"]\n",
    "        return {\n",
    "            \"date\": date,\n",
    "            \"recovery_score\": score.get(\"recovery_score\"),\n",
    "            \"resting_heart_rate\": score.get(\"resting_heart_rate\"),\n",
    "            \"heart_rate_variability\": score.get(\"hrv_rmssd_milli\"),\n",
    "            \"spo2_percentage\": score.get(\"spo2_percentage\"),\n",
    "            \"skin_temperature_celsius\": score.get(\"skin_temp_celsius\")\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # fallback for unexpected API issues or parsing errors\n",
    "        return {\"error\": f\"{type(e).__name__}: {e}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strain_from_cycle_for_date(date: str):\n",
    "    \"\"\"\n",
    "    Get WHOOP strain metrics for a specific date.\n",
    "\n",
    "    Args:\n",
    "        date (str): Date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "        dict: Strain score and related metrics, or an error/message if unavailable.\n",
    "    \"\"\"\n",
    "    start = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    end = start + timedelta(days=1)\n",
    "\n",
    "    # Convert to ISO 8601 format with a 'Z' to indicate UTC\n",
    "    start_iso = start.isoformat(timespec='seconds') + \"Z\"\n",
    "    end_iso = end.isoformat(timespec='seconds') + \"Z\"\n",
    "\n",
    "    # Query the WHOOP cycle endpoint for strain data\n",
    "    url = f\"https://api.prod.whoop.com/developer/v1/cycle?start={start_iso}&end={end_iso}\"\n",
    "    resp = oauth.get(url)\n",
    "\n",
    "    try:\n",
    "        data = resp.json()\n",
    "        records = data.get(\"records\", [])\n",
    "\n",
    "        if not records:\n",
    "            return {\"message\": \"No cycle/strain data found for that date\"}\n",
    "\n",
    "        score = records[0].get(\"score\", {})\n",
    "        return {\n",
    "            \"date\": date,\n",
    "            \"strain_score\": score.get(\"strain\"),\n",
    "            \"kilojoules\": score.get(\"kilojoule\"),\n",
    "            \"average_heart_rate\": score.get(\"average_heart_rate\"),\n",
    "            \"max_heart_rate\": score.get(\"max_heart_rate\"),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fallback in case of API or parsing errors\n",
    "        return {\"error\": f\"{type(e).__name__}: {e}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleep_data_for_date(date: str):\n",
    "    \"\"\"\n",
    "    Get WHOOP sleep data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): Date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "        dict: Sleep summary with stage durations, sleep score, and other key metrics.\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # Define start and end of the requested day\n",
    "    start = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    end = start + timedelta(days=1)\n",
    "    start_iso = start.isoformat(timespec='seconds') + \"Z\"\n",
    "    end_iso = end.isoformat(timespec='seconds') + \"Z\"\n",
    "\n",
    "    # WHOOP sleep activity endpoint\n",
    "    url = f\"https://api.prod.whoop.com/developer/v1/activity/sleep?start={start_iso}&end={end_iso}\"\n",
    "    resp = oauth.get(url)\n",
    "\n",
    "    try:\n",
    "        data = resp.json()\n",
    "        records = data.get(\"records\", [])\n",
    "\n",
    "        if not records:\n",
    "            return {\"message\": \"No sleep data found for that date\"}\n",
    "\n",
    "        sleep = records[0]\n",
    "        score = sleep.get(\"score\", {})\n",
    "        stage_summary = score.get(\"stage_summary\", {})\n",
    "\n",
    "        # Convert stage durations from milliseconds to minutes\n",
    "        light = stage_summary.get(\"total_light_sleep_time_milli\", 0) // 60000\n",
    "        slow = stage_summary.get(\"total_slow_wave_sleep_time_milli\", 0) // 60000\n",
    "        rem = stage_summary.get(\"total_rem_sleep_time_milli\", 0) // 60000\n",
    "        awake = stage_summary.get(\"total_awake_time_milli\", 0) // 60000\n",
    "        in_bed = stage_summary.get(\"total_in_bed_time_milli\", 0) // 60000\n",
    "\n",
    "        total_sleep = light + slow + rem\n",
    "\n",
    "        return {\n",
    "            \"date\": date,\n",
    "            \"total_sleep_minutes\": total_sleep,\n",
    "            \"sleep_score\": score.get(\"sleep_performance_percentage\"),\n",
    "            \"sleep_efficiency_percent\": score.get(\"sleep_efficiency_percentage\"),\n",
    "            \"sleep_consistency_percent\": score.get(\"sleep_consistency_percentage\"),\n",
    "            \"respiratory_rate\": score.get(\"respiratory_rate\"),\n",
    "            \"stages\": {\n",
    "                \"light_sleep_minutes\": light,\n",
    "                \"slow_wave_sleep_minutes\": slow,\n",
    "                \"rem_sleep_minutes\": rem,\n",
    "                \"awake_minutes\": awake,\n",
    "                \"in_bed_minutes\": in_bed\n",
    "            }\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return both error message and raw response for debugging\n",
    "        return {\"error\": f\"{type(e).__name__}: {e}\", \"raw\": resp.text}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOpbUJYOCL35"
   },
   "source": [
    "# Assistant Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZdm-hOICRGs"
   },
   "source": [
    "### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi_GZGsACTr7"
   },
   "source": [
    "### Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools (APIs and capabilities) the assistant can use\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get weather for a specific date\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date\": {\"type\": \"string\", \"description\": \"Date in YYYY-MM-DD\"},\n",
    "                },\n",
    "                \"required\": [\"date\", \"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_cleaned_recovery_for_date\",\n",
    "            \"description\": \"Fetch WHOOP recovery metrics for a given date.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date\": {\"type\": \"string\", \"description\": \"Date in YYYY-MM-DD\"}\n",
    "                },\n",
    "                \"required\": [\"date\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_strain_from_cycle_for_date\",\n",
    "            \"description\": \"Fetch WHOOP strain metrics for a given date.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date\": {\"type\": \"string\", \"description\": \"Date in YYYY-MM-DD\"}\n",
    "                },\n",
    "                \"required\": [\"date\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_sleep_data_for_date\",\n",
    "            \"description\": \"Fetch WHOOP sleep metrics for a specific date, including total sleep, efficiency, and sleep stages.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date\": {\"type\": \"string\", \"description\": \"Date in YYYY-MM-DD\"}\n",
    "                },\n",
    "                \"required\": [\"date\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"fetch_and_parse_notion_entries\",\n",
    "            \"description\": \"Retrieve quantified productivity data from Notion for a specific date, including deep work, off-task time, light work time, break time, neutral/life admin time, and total hours.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date\": {\"type\": \"string\", \"description\": \"Date in YYYY-MM-DD format\"}\n",
    "                },\n",
    "                \"required\": [\"date\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\"type\": \"file_search\"},\n",
    "    {\"type\": \"code_interpreter\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgD25oPJCbV9"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        uploaded = client.files.create(file=f, purpose=\"assistants\")\n",
    "    return uploaded.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store_with_file(file_path):\n",
    "    # Create a new vector store\n",
    "    vector_store = client.vector_stores.create(name=\"Jounral Vector Store\")\n",
    "    # Open the file in binary read mode\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        # Upload the file to the vector store\n",
    "        file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "            vector_store_id=vector_store.id,\n",
    "            files=[f]\n",
    "        )\n",
    "\n",
    "    # Check if the upload was successful\n",
    "    if file_batch.status != \"completed\":\n",
    "        raise RuntimeError(\"Vector store file batch did not complete\")\n",
    "\n",
    "    return vector_store.id\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_vector_store_to_assistant(assistant_id, vector_store_id):\n",
    "    updated = client.beta.assistants.update(\n",
    "        assistant_id=assistant_id,\n",
    "        tool_resources={\n",
    "            \"file_search\": {\n",
    "                \"vector_store_ids\": [vector_store_id]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_assistant(file_path):\n",
    "    # Upload and attach vector store\n",
    "    vector_store_id = create_vector_store_with_file(file_path)\n",
    "\n",
    "    # Create the assistant\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Hamming Productivity Coach v2.3\",\n",
    "        instructions=instructions,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    # Attach vector store to assistant\n",
    "    updated = attach_vector_store_to_assistant(assistant.id, vector_store_id)\n",
    "\n",
    "    return updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_thread_with_file_search(thread, assistant_id):\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Can you find the journal entry for 2025-04-15?\"\n",
    "    )\n",
    "    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)\n",
    "\n",
    "    # Wait for file_search completion\n",
    "    while True:\n",
    "        run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        if run_status.status == \"completed\":\n",
    "            break\n",
    "        elif run_status.status == \"failed\":\n",
    "            raise RuntimeError(\"Priming run failed\")\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You are a data-driven assistant providing clear, insightful analysis of journal entries, productivity patterns, biometric performance (WHOOP), and environmental context (e.g., weather). Your goal is to surface useful trends, correlations, and actionable recommendations to improve the user's mental clarity, physical recovery, and daily performance.\n",
    "\n",
    "You have access to the following tools. Use them exactly as described:\n",
    "\n",
    "- Use 'get_weather' to retrieve weather conditions for a specific date.\n",
    "- Use 'get_cleaned_recovery_for_date' for WHOOP recovery metrics (e.g., HRV, RHR, Recovery Score).\n",
    "- Use 'get_strain_from_cycle_for_date' for WHOOP strain metrics and heart rate data for a date.\n",
    "- Use 'get_sleep_data_for_date' for WHOOP sleep metrics (e.g., total sleep, efficiency, REM, SWS).\n",
    "- Use 'fetch_and_parse_notion_entries' to retrieve structured productivity metrics (deep work, break time, off-task time, etc.) for a specific date.\n",
    "- Use 'file_search' to retrieve journal entries from uploaded text files. Always call it with a JSON object like: { \"query\": \"2025-04-26 journal entry\" }.\n",
    "- Use 'code_interpreter' for all numerical or data relationship analysis — including calculating correlations, generating visualizations, comparing trends, and summarizing data patterns. Always prefer 'code_interpreter' for any statistical or graphical task.\n",
    "\n",
    "For weekly or multi-day reports, prioritize these mappings:\n",
    "- **Mental health insights** should be primarily drawn from patterns and sentiment in the journal entries (use 'file_search').\n",
    "- **Productivity trends** should rely mostly on the structured time-tracking data from Notion (via 'fetch_and_parse_notion_entries').\n",
    "- **Wellness and health patterns** should be informed by WHOOP biometric data (recovery, sleep, and strain) and weather conditions.\n",
    "\n",
    "Always analyze across multiple days when relevant to extract trends or cause-effect patterns between mood, focus, recovery, strain, sleep, weather, and productivity. Use the tools above to collect relevant data, then use 'code_interpreter' to analyze and visualize relationships.\n",
    "\n",
    "When generating visualizations:\n",
    "- Label axes and legends clearly.\n",
    "- Choose the best graph type for the data (e.g., line chart for time trends, scatterplot for correlations, bar chart for comparisons).\n",
    "- Summarize key takeaways immediately after the chart.\n",
    "- Always relate the visual insight back to the user’s performance, well-being, or decision-making.\n",
    "\n",
    "Avoid generic summaries — focus on:\n",
    "- Identifying causes behind good or poor performance days.\n",
    "- Finding meaningful correlations (e.g., between REM sleep and mood, or screen time and recovery).\n",
    "- Making smart, personalized suggestions grounded in observed data patterns.\n",
    "\n",
    "Be practical, insightful, and user-focused in your coaching.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_mvli0ECg-f"
   },
   "source": [
    "## Assistant Interaction Logic\n",
    "\n",
    "This function is the core of user-assistant interaction. It handles:\n",
    "\n",
    "- Sending user messages to the assistant\n",
    "- Waiting for responses or tool calls\n",
    "- Automatically handling all tool calls (weather, WHOOP, Notion, etc.) with local function implementations\n",
    "- Timeout logic to prevent infinite loops (after 240 seconds)\n",
    "- Collecting text and any returned images (e.g., from `code_interpreter` graphs)\n",
    "\n",
    "###  Error Handling and Robustness\n",
    "- All tool arguments are parsed and validated before use\n",
    "- If tool output generation fails, the assistant reports an error gracefully\n",
    "- If the assistant takes too long to respond, it returns a timeout message\n",
    "- Ensures the user is **never stuck waiting** or left without feedback\n",
    "\n",
    "This modular structure makes the assistant both **resilient** and **interactive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_with_assistant(assistant, thread, message, timeout_seconds=240):\n",
    "    \"\"\"\n",
    "    Send a message to the assistant and handle the full interaction, including tool calls and timeout.\n",
    "\n",
    "    Args:\n",
    "        assistant: The OpenAI assistant object.\n",
    "        thread: The conversation thread object.\n",
    "        message (str): User message to send.\n",
    "        timeout_seconds (int): Max time to wait for completion before giving up.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains the assistant's final text response and any returned image data.\n",
    "    \"\"\"\n",
    "    # Send user message to thread\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=message)\n",
    "    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)\n",
    "    assistant_info = client.beta.assistants.retrieve(assistant.id)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "        # Timeout handling\n",
    "        if time.time() - start_time > timeout_seconds:\n",
    "            return {\n",
    "                \"text\": \"(Timeout: Assistant took too long to respond. Create a new Assistant and Thread)\",\n",
    "                \"images\": []\n",
    "            }\n",
    "\n",
    "        # If assistant requests tool actions\n",
    "        if run_status.status == \"requires_action\":\n",
    "            tool_calls = run_status.required_action.submit_tool_outputs.tool_calls\n",
    "            outputs = []\n",
    "\n",
    "            for call in tool_calls:\n",
    "                try:\n",
    "                    args = json.loads(call.function.arguments)\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed to parse arguments for tool '{call.function.name}': {e}\")\n",
    "                    raise\n",
    "\n",
    "                name = call.function.name\n",
    "\n",
    "                # Route tool calls to local function handlers\n",
    "                if name == \"get_weather\":\n",
    "                    output = get_weather(**args)\n",
    "                elif name == \"get_cleaned_recovery_for_date\":\n",
    "                    output = json.dumps(get_cleaned_recovery_for_date(**args))\n",
    "                elif name == \"get_strain_from_cycle_for_date\":\n",
    "                    output = json.dumps(get_strain_from_cycle_for_date(**args))\n",
    "                elif name == \"get_sleep_data_for_date\":\n",
    "                    output = json.dumps(get_sleep_data_for_date(**args))\n",
    "                elif name == \"fetch_and_parse_notion_entries\":\n",
    "                    output = json.dumps(fetch_and_parse_notion_entries(**args))\n",
    "                else:\n",
    "                    output = f\"No local handler implemented for {name}\"\n",
    "\n",
    "                outputs.append({\n",
    "                    \"tool_call_id\": call.id,\n",
    "                    \"output\": output\n",
    "                })\n",
    "\n",
    "            # Submit tool outputs back to assistant\n",
    "            run = client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=outputs\n",
    "            )\n",
    "\n",
    "        elif run_status.status == \"completed\":\n",
    "            break\n",
    "        elif run_status.status == \"failed\":\n",
    "            raise Exception(\"Assistant run failed\")\n",
    "\n",
    "    # Once run is completed, fetch and parse the latest assistant response\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    latest_message_text = None\n",
    "    image_data_list = []\n",
    "\n",
    "    for content_block in messages.data[0].content:\n",
    "        if content_block.type == \"text\":\n",
    "            latest_message_text = content_block.text.value.strip()\n",
    "        elif content_block.type == \"image_file\":\n",
    "            image_file_id = content_block.image_file.file_id\n",
    "            image_content = client.files.content(file_id=image_file_id)\n",
    "            image_bytes = b\"\".join(image_content.iter_bytes())\n",
    "            image_data_list.append(image_bytes)\n",
    "\n",
    "    # If nothing was returned, show fallback message\n",
    "    if latest_message_text is None and not image_data_list:\n",
    "        return {\n",
    "            \"text\": \"(No content returned.)\",\n",
    "            \"images\": []\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"text\": latest_message_text,\n",
    "        \"images\": image_data_list\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgDKwvrBDIPu"
   },
   "source": [
    "# Launching AURA & Create a New Assistant\n",
    "\n",
    "> Run the cell below **every time you want to start a new assistant**.\n",
    "\n",
    "This cell:\n",
    "- Creates a new assistant\n",
    "- Sets up a persistent thread\n",
    "- Primes the assistant using the file search tool (run twice for better context retention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create  assistant ( needs to be done each time a new conversation is starting)\n",
    "\n",
    "assistant = create_new_assistant(\"April_2025_Journal_Entries.txt\")\n",
    "\n",
    "# Create a persistent thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Repeated twice for solid priming\n",
    "prime_thread_with_file_search(thread, assistant.id)\n",
    "prime_thread_with_file_search(thread, assistant.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1Sf5bcVgEXZ"
   },
   "source": [
    "\n",
    "# Interactive Chat Interface\n",
    "\n",
    "This widget lets you talk to the assistant and see responses in real time.\n",
    "\n",
    "### Example Prompts to Try:\n",
    "- `\"what was my mood and head-space at based on my journal entries from the 14th to 20th of April 2025\"`\n",
    "- `\"How was my sleep and productivity on the 19th of April 2025.\"`\n",
    "- `\"Was there any pattern between deep work and sleep quality form the 14th to the 20th of April? Find any correlations and plot the relationship\"`\n",
    "- `\"Compare my recovery scores to my productivity form the 14th to the 20th of April. Use a visualisation\"`\n",
    "\n",
    "\n",
    ">  **Important Design Note:**  \n",
    "> The assistant can sometimes ( not always) be overloaded if asked to use all the tools together for a long period of time. To prevent confusion or overload, the user is expected to use a few prompts to extract all the information and analysis for a time period.\n",
    "\n",
    "\n",
    "> **Re-running Assistant Note**:  \n",
    "> if you want to start a new conversation, run the cell above and create a new assistant and thread, and rerun the cell below.\n",
    "\n",
    "> If you get an error for whatever reason you'll need to rerun the assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f086499a52547e0b0a92d7cf4de2bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e4ab82495a460ead063839c523de78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='User:', layout=Layout(height='150px', width='100%'), placeholder='Ask a questi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be57f6bbe28b4591b099879759854e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Send', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Output widget to display full conversation history\n",
    "chat_history = widgets.Output()\n",
    "\n",
    "# Text input and send button\n",
    "input_box = widgets.Textarea(\n",
    "    placeholder='Ask a question or follow up...',\n",
    "    description='User:',\n",
    "    layout=widgets.Layout(width='100%', height='150px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "submit_button = widgets.Button(description=\"Send\", button_style='info')\n",
    "\n",
    "# Callback for the button\n",
    "def on_submit(b):\n",
    "    user_input = input_box.value.strip()\n",
    "    if user_input == \"\":\n",
    "        return\n",
    "\n",
    "    # Disable the button and show waiting status\n",
    "    submit_button.disabled = True\n",
    "    submit_button.description = \"Waiting...\"\n",
    "\n",
    "    # Display user message and placeholder\n",
    "    with chat_history:\n",
    "        display(Markdown(f\"**User:**\\n\\n{user_input}\"))\n",
    "        display(Markdown(\"**Assistant:** _(thinking...)_\"))\n",
    "\n",
    "    try:\n",
    "        response = interact_with_assistant(assistant, thread, user_input)\n",
    "        if isinstance(response, str):\n",
    "            # fallback in case response is incorrectly formatted\n",
    "            response = {\"text\": response, \"images\": []}\n",
    "    except Exception as e:\n",
    "        response = {\"text\": f\"(Error: {str(e)})\", \"images\": []}\n",
    "\n",
    "    # Display response content\n",
    "    with chat_history:\n",
    "        if response.get(\"text\"):\n",
    "            display(Markdown(f\"**Assistant:**\\n\\n{response['text']}\"))\n",
    "        for img_bytes in response.get(\"images\", []):\n",
    "            display(Image(data=img_bytes, format='PNG'))\n",
    "\n",
    "    # Reset\n",
    "    input_box.value = \"\"\n",
    "    submit_button.disabled = False\n",
    "    submit_button.description = \"Send\"\n",
    "\n",
    "# Connect and display\n",
    "submit_button.on_click(on_submit)\n",
    "display(chat_history)\n",
    "display(input_box, submit_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq_07yGDmHS2"
   },
   "source": [
    "# Previous Worked Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNH1qPyyOM3b"
   },
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c8a0e6b0e94339a452735389d34f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86e87c693014f6894bb88064751ec5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='User:', layout=Layout(height='150px', width='100%'), placeholder='Ask a questi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc68c6d794547c1abbf2b71d62e3d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Send', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Output widget to display full conversation history\n",
    "chat_history = widgets.Output()\n",
    "\n",
    "# Text input and send button\n",
    "input_box = widgets.Textarea(\n",
    "    placeholder='Ask a question or follow up...',\n",
    "    description='User:',\n",
    "    layout=widgets.Layout(width='100%', height='150px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "submit_button = widgets.Button(description=\"Send\", button_style='info')\n",
    "\n",
    "# Callback for the button\n",
    "def on_submit(b):\n",
    "    user_input = input_box.value.strip()\n",
    "    if user_input == \"\":\n",
    "        return\n",
    "\n",
    "    # Disable the button and show waiting status\n",
    "    submit_button.disabled = True\n",
    "    submit_button.description = \"Waiting...\"\n",
    "\n",
    "    # Display user message and placeholder\n",
    "    with chat_history:\n",
    "        display(Markdown(f\"**User:**\\n\\n{user_input}\"))\n",
    "        display(Markdown(\"**Assistant:** _(thinking...)_\"))\n",
    "\n",
    "    try:\n",
    "        response = interact_with_assistant(assistant, thread, user_input)\n",
    "        if isinstance(response, str):\n",
    "            # fallback in case response is incorrectly formatted\n",
    "            response = {\"text\": response, \"images\": []}\n",
    "    except Exception as e:\n",
    "        response = {\"text\": f\"(Error: {str(e)})\", \"images\": []}\n",
    "\n",
    "    # Display response content\n",
    "    with chat_history:\n",
    "        if response.get(\"text\"):\n",
    "            display(Markdown(f\"**Assistant:**\\n\\n{response['text']}\"))\n",
    "        for img_bytes in response.get(\"images\", []):\n",
    "            display(Image(data=img_bytes, format='PNG'))\n",
    "\n",
    "    # Reset\n",
    "    input_box.value = \"\"\n",
    "    submit_button.disabled = False\n",
    "    submit_button.description = \"Send\"\n",
    "\n",
    "# Connect and display\n",
    "submit_button.on_click(on_submit)\n",
    "display(chat_history)\n",
    "display(input_box, submit_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLumPSNrqEyg"
   },
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c07e9d76ff4dcaabbf545a314db7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4199518cdd48465b94dec6a60d1a403f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='User:', layout=Layout(height='150px', width='100%'), placeholder='Ask a questi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70028b288944df6ad1accce729abb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Send', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Output widget to display full conversation history\n",
    "chat_history = widgets.Output()\n",
    "\n",
    "# Text input and send button\n",
    "input_box = widgets.Textarea(\n",
    "    placeholder='Ask a question or follow up...',\n",
    "    description='User:',\n",
    "    layout=widgets.Layout(width='100%', height='150px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "submit_button = widgets.Button(description=\"Send\", button_style='info')\n",
    "\n",
    "# Callback for the button\n",
    "def on_submit(b):\n",
    "    user_input = input_box.value.strip()\n",
    "    if user_input == \"\":\n",
    "        return\n",
    "\n",
    "    # Disable the button and show waiting status\n",
    "    submit_button.disabled = True\n",
    "    submit_button.description = \"Waiting...\"\n",
    "\n",
    "    # Display user message and placeholder\n",
    "    with chat_history:\n",
    "        display(Markdown(f\"**User:**\\n\\n{user_input}\"))\n",
    "        display(Markdown(\"**Assistant:** _(thinking...)_\"))\n",
    "\n",
    "    try:\n",
    "        response = interact_with_assistant(assistant, thread, user_input)\n",
    "        if isinstance(response, str):\n",
    "            # fallback in case response is incorrectly formatted\n",
    "            response = {\"text\": response, \"images\": []}\n",
    "    except Exception as e:\n",
    "        response = {\"text\": f\"(Error: {str(e)})\", \"images\": []}\n",
    "\n",
    "    # Display response content\n",
    "    with chat_history:\n",
    "        if response.get(\"text\"):\n",
    "            display(Markdown(f\"**Assistant:**\\n\\n{response['text']}\"))\n",
    "        for img_bytes in response.get(\"images\", []):\n",
    "            display(Image(data=img_bytes, format='PNG'))\n",
    "\n",
    "    # Reset\n",
    "    input_box.value = \"\"\n",
    "    submit_button.disabled = False\n",
    "    submit_button.description = \"Send\"\n",
    "\n",
    "# Connect and display\n",
    "submit_button.on_click(on_submit)\n",
    "display(chat_history)\n",
    "display(input_box, submit_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWg0yi3SqOo1"
   },
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae8092679144504b8730aaee0bc9a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0710579d515e415494bdcee371f5a6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='User:', layout=Layout(height='150px', width='100%'), placeholder='Ask a questi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d1a6715caa44bea2629c52b08fa0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Send', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Output widget to display full conversation history\n",
    "chat_history = widgets.Output()\n",
    "\n",
    "# Text input and send button\n",
    "input_box = widgets.Textarea(\n",
    "    placeholder='Ask a question or follow up...',\n",
    "    description='User:',\n",
    "    layout=widgets.Layout(width='100%', height='150px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "submit_button = widgets.Button(description=\"Send\", button_style='info')\n",
    "\n",
    "# Callback for the button\n",
    "def on_submit(b):\n",
    "    user_input = input_box.value.strip()\n",
    "    if user_input == \"\":\n",
    "        return\n",
    "\n",
    "    # Disable the button and show waiting status\n",
    "    submit_button.disabled = True\n",
    "    submit_button.description = \"Waiting...\"\n",
    "\n",
    "    # Display user message and placeholder\n",
    "    with chat_history:\n",
    "        display(Markdown(f\"**User:**\\n\\n{user_input}\"))\n",
    "        display(Markdown(\"**Assistant:** _(thinking...)_\"))\n",
    "\n",
    "    try:\n",
    "        response = interact_with_assistant(assistant, thread, user_input)\n",
    "        if isinstance(response, str):\n",
    "            # fallback in case response is incorrectly formatted\n",
    "            response = {\"text\": response, \"images\": []}\n",
    "    except Exception as e:\n",
    "        response = {\"text\": f\"(Error: {str(e)})\", \"images\": []}\n",
    "\n",
    "    # Display response content\n",
    "    with chat_history:\n",
    "        if response.get(\"text\"):\n",
    "            display(Markdown(f\"**Assistant:**\\n\\n{response['text']}\"))\n",
    "        for img_bytes in response.get(\"images\", []):\n",
    "            display(Image(data=img_bytes, format='PNG'))\n",
    "\n",
    "    # Reset\n",
    "    input_box.value = \"\"\n",
    "    submit_button.disabled = False\n",
    "    submit_button.description = \"Send\"\n",
    "\n",
    "# Connect and display\n",
    "submit_button.on_click(on_submit)\n",
    "display(chat_history)\n",
    "display(input_box, submit_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
